{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MB.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bCRGUsR0oj_3"},"source":["<center> Adversarial attacks <center>\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66gNbeg56JDk","executionInfo":{"status":"ok","timestamp":1606830097412,"user_tz":-60,"elapsed":21626,"user":{"displayName":"Barbieri Matteo","photoUrl":"","userId":"12756688091763181975"}},"outputId":"a2b8bbea-2013-40c4-8bd5-3117274cd48a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVYtwIZuyBhg","executionInfo":{"status":"ok","timestamp":1606830098214,"user_tz":-60,"elapsed":22413,"user":{"displayName":"Barbieri Matteo","photoUrl":"","userId":"12756688091763181975"}},"outputId":"7d9782ae-e0ca-41fc-cc2f-23711768f05e"},"source":["import os\n","%cd '/content/drive/MyDrive/Colab Notebooks/assignment_3'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/assignment_3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sgtqlXstMCdc"},"source":["import matplotlib.pyplot as plt\n","import tensorflow.keras as keras\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from cifar_utils import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QTwnGf28oCLj"},"source":["1- Import the cifar dataset"]},{"cell_type":"code","metadata":{"id":"JHdSGnFToFUw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606830116063,"user_tz":-60,"elapsed":40252,"user":{"displayName":"Barbieri Matteo","photoUrl":"","userId":"12756688091763181975"}},"outputId":"8ad19717-cc37-4444-ed98-37799e9b9794"},"source":["x_train, train_labels, x_test, test_labels = load_CIFAR10_data()\n","classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vAIGKd4poUwq"},"source":["#plt.imshow(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFBALtYMobhv"},"source":["2- Train a base model"]},{"cell_type":"code","metadata":{"id":"AOe9UUlkmGNX"},"source":["input_shape = (32,32,3)\n","model = build_model_base_CNN(input_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ITv10wcmNr-"},"source":["#model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"biz2Bi_1n86r","executionInfo":{"status":"ok","timestamp":1606830421627,"user_tz":-60,"elapsed":300398,"user":{"displayName":"Barbieri Matteo","photoUrl":"","userId":"12756688091763181975"}},"outputId":"da9c9d8f-9c8b-46ce-d4dc-9a67e03ec1b8"},"source":["## hot encoding of the labels\n","y_train = keras.utils.to_categorical(train_labels, 10) \n","y_test = keras.utils.to_categorical(test_labels, 10)\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=15)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","history = model.fit(x_train, y_train, epochs=100, batch_size=64,verbose=1,validation_split = 0.2,callbacks=[es,mc])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","619/625 [============================>.] - ETA: 0s - loss: 2.0992 - accuracy: 0.2089\n","Epoch 00001: val_accuracy improved from -inf to 0.36660, saving model to best_model.h5\n","625/625 [==============================] - 4s 7ms/step - loss: 2.0965 - accuracy: 0.2101 - val_loss: 1.7378 - val_accuracy: 0.3666\n","Epoch 2/100\n","619/625 [============================>.] - ETA: 0s - loss: 1.7141 - accuracy: 0.3685\n","Epoch 00002: val_accuracy improved from 0.36660 to 0.43910, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.7128 - accuracy: 0.3692 - val_loss: 1.5588 - val_accuracy: 0.4391\n","Epoch 3/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.5695 - accuracy: 0.4223\n","Epoch 00003: val_accuracy improved from 0.43910 to 0.48080, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.5693 - accuracy: 0.4222 - val_loss: 1.4436 - val_accuracy: 0.4808\n","Epoch 4/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.4681 - accuracy: 0.4634\n","Epoch 00004: val_accuracy improved from 0.48080 to 0.51440, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.4678 - accuracy: 0.4637 - val_loss: 1.3438 - val_accuracy: 0.5144\n","Epoch 5/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.3903 - accuracy: 0.4947\n","Epoch 00005: val_accuracy improved from 0.51440 to 0.54530, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.3909 - accuracy: 0.4944 - val_loss: 1.2890 - val_accuracy: 0.5453\n","Epoch 6/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.3232 - accuracy: 0.5213\n","Epoch 00006: val_accuracy improved from 0.54530 to 0.56140, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.3235 - accuracy: 0.5210 - val_loss: 1.2329 - val_accuracy: 0.5614\n","Epoch 7/100\n","621/625 [============================>.] - ETA: 0s - loss: 1.2614 - accuracy: 0.5467\n","Epoch 00007: val_accuracy improved from 0.56140 to 0.59550, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.2612 - accuracy: 0.5469 - val_loss: 1.1342 - val_accuracy: 0.5955\n","Epoch 8/100\n","619/625 [============================>.] - ETA: 0s - loss: 1.2084 - accuracy: 0.5644\n","Epoch 00008: val_accuracy improved from 0.59550 to 0.60070, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.2080 - accuracy: 0.5650 - val_loss: 1.1288 - val_accuracy: 0.6007\n","Epoch 9/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.1606 - accuracy: 0.5847\n","Epoch 00009: val_accuracy improved from 0.60070 to 0.61500, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.1603 - accuracy: 0.5847 - val_loss: 1.0789 - val_accuracy: 0.6150\n","Epoch 10/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.1242 - accuracy: 0.5989\n","Epoch 00010: val_accuracy improved from 0.61500 to 0.62590, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.1250 - accuracy: 0.5986 - val_loss: 1.0668 - val_accuracy: 0.6259\n","Epoch 11/100\n","620/625 [============================>.] - ETA: 0s - loss: 1.0771 - accuracy: 0.6136\n","Epoch 00011: val_accuracy improved from 0.62590 to 0.65760, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.0776 - accuracy: 0.6132 - val_loss: 0.9688 - val_accuracy: 0.6576\n","Epoch 12/100\n","618/625 [============================>.] - ETA: 0s - loss: 1.0450 - accuracy: 0.6269\n","Epoch 00012: val_accuracy improved from 0.65760 to 0.66280, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.0448 - accuracy: 0.6268 - val_loss: 0.9617 - val_accuracy: 0.6628\n","Epoch 13/100\n","621/625 [============================>.] - ETA: 0s - loss: 1.0110 - accuracy: 0.6397\n","Epoch 00013: val_accuracy improved from 0.66280 to 0.67420, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 1.0112 - accuracy: 0.6395 - val_loss: 0.9201 - val_accuracy: 0.6742\n","Epoch 14/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.9840 - accuracy: 0.6523\n","Epoch 00014: val_accuracy did not improve from 0.67420\n","625/625 [==============================] - 4s 6ms/step - loss: 0.9839 - accuracy: 0.6524 - val_loss: 0.9224 - val_accuracy: 0.6720\n","Epoch 15/100\n","621/625 [============================>.] - ETA: 0s - loss: 0.9594 - accuracy: 0.6587\n","Epoch 00015: val_accuracy improved from 0.67420 to 0.68720, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.9588 - accuracy: 0.6589 - val_loss: 0.8802 - val_accuracy: 0.6872\n","Epoch 16/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.6683\n","Epoch 00016: val_accuracy improved from 0.68720 to 0.70430, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.9299 - accuracy: 0.6679 - val_loss: 0.8414 - val_accuracy: 0.7043\n","Epoch 17/100\n","621/625 [============================>.] - ETA: 0s - loss: 0.9030 - accuracy: 0.6794\n","Epoch 00017: val_accuracy did not improve from 0.70430\n","625/625 [==============================] - 4s 6ms/step - loss: 0.9042 - accuracy: 0.6791 - val_loss: 0.8838 - val_accuracy: 0.6918\n","Epoch 18/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.8865 - accuracy: 0.6856\n","Epoch 00018: val_accuracy improved from 0.70430 to 0.70480, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.8864 - accuracy: 0.6856 - val_loss: 0.8339 - val_accuracy: 0.7048\n","Epoch 19/100\n","621/625 [============================>.] - ETA: 0s - loss: 0.8608 - accuracy: 0.6938\n","Epoch 00019: val_accuracy improved from 0.70480 to 0.72460, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.8610 - accuracy: 0.6938 - val_loss: 0.7901 - val_accuracy: 0.7246\n","Epoch 20/100\n","621/625 [============================>.] - ETA: 0s - loss: 0.8425 - accuracy: 0.7006\n","Epoch 00020: val_accuracy did not improve from 0.72460\n","625/625 [==============================] - 4s 6ms/step - loss: 0.8426 - accuracy: 0.7007 - val_loss: 0.7843 - val_accuracy: 0.7212\n","Epoch 21/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.7101\n","Epoch 00021: val_accuracy improved from 0.72460 to 0.73000, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.8225 - accuracy: 0.7101 - val_loss: 0.7620 - val_accuracy: 0.7300\n","Epoch 22/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.8066 - accuracy: 0.7134\n","Epoch 00022: val_accuracy did not improve from 0.73000\n","625/625 [==============================] - 4s 6ms/step - loss: 0.8067 - accuracy: 0.7135 - val_loss: 0.8013 - val_accuracy: 0.7199\n","Epoch 23/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.7906 - accuracy: 0.7211\n","Epoch 00023: val_accuracy improved from 0.73000 to 0.74090, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7909 - accuracy: 0.7211 - val_loss: 0.7367 - val_accuracy: 0.7409\n","Epoch 24/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.7767 - accuracy: 0.7256\n","Epoch 00024: val_accuracy did not improve from 0.74090\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7762 - accuracy: 0.7258 - val_loss: 0.7338 - val_accuracy: 0.7365\n","Epoch 25/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.7590 - accuracy: 0.7312\n","Epoch 00025: val_accuracy improved from 0.74090 to 0.74360, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7588 - accuracy: 0.7314 - val_loss: 0.7223 - val_accuracy: 0.7436\n","Epoch 26/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.7440 - accuracy: 0.7384\n","Epoch 00026: val_accuracy improved from 0.74360 to 0.74950, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7448 - accuracy: 0.7381 - val_loss: 0.7157 - val_accuracy: 0.7495\n","Epoch 27/100\n","621/625 [============================>.] - ETA: 0s - loss: 0.7306 - accuracy: 0.7410\n","Epoch 00027: val_accuracy did not improve from 0.74950\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7305 - accuracy: 0.7410 - val_loss: 0.7143 - val_accuracy: 0.7470\n","Epoch 28/100\n","616/625 [============================>.] - ETA: 0s - loss: 0.7164 - accuracy: 0.7458\n","Epoch 00028: val_accuracy improved from 0.74950 to 0.75200, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7167 - accuracy: 0.7459 - val_loss: 0.7000 - val_accuracy: 0.7520\n","Epoch 29/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.7041 - accuracy: 0.7521\n","Epoch 00029: val_accuracy improved from 0.75200 to 0.75940, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.7040 - accuracy: 0.7518 - val_loss: 0.6887 - val_accuracy: 0.7594\n","Epoch 30/100\n","625/625 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7555\n","Epoch 00030: val_accuracy improved from 0.75940 to 0.75970, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6923 - accuracy: 0.7555 - val_loss: 0.6771 - val_accuracy: 0.7597\n","Epoch 31/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.7604\n","Epoch 00031: val_accuracy improved from 0.75970 to 0.77060, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6812 - accuracy: 0.7599 - val_loss: 0.6577 - val_accuracy: 0.7706\n","Epoch 32/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.7634\n","Epoch 00032: val_accuracy did not improve from 0.77060\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6696 - accuracy: 0.7634 - val_loss: 0.6515 - val_accuracy: 0.7667\n","Epoch 33/100\n","616/625 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7670\n","Epoch 00033: val_accuracy did not improve from 0.77060\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6585 - accuracy: 0.7669 - val_loss: 0.6592 - val_accuracy: 0.7681\n","Epoch 34/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.7716\n","Epoch 00034: val_accuracy improved from 0.77060 to 0.77170, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6485 - accuracy: 0.7712 - val_loss: 0.6479 - val_accuracy: 0.7717\n","Epoch 35/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.6334 - accuracy: 0.7767\n","Epoch 00035: val_accuracy improved from 0.77170 to 0.77770, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6347 - accuracy: 0.7764 - val_loss: 0.6263 - val_accuracy: 0.7777\n","Epoch 36/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.6270 - accuracy: 0.7792\n","Epoch 00036: val_accuracy improved from 0.77770 to 0.77790, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6277 - accuracy: 0.7790 - val_loss: 0.6282 - val_accuracy: 0.7779\n","Epoch 37/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.6223 - accuracy: 0.7805\n","Epoch 00037: val_accuracy improved from 0.77790 to 0.77800, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6224 - accuracy: 0.7806 - val_loss: 0.6325 - val_accuracy: 0.7780\n","Epoch 38/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.6079 - accuracy: 0.7860\n","Epoch 00038: val_accuracy improved from 0.77800 to 0.77960, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6079 - accuracy: 0.7860 - val_loss: 0.6217 - val_accuracy: 0.7796\n","Epoch 39/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.7871\n","Epoch 00039: val_accuracy did not improve from 0.77960\n","625/625 [==============================] - 4s 6ms/step - loss: 0.6022 - accuracy: 0.7872 - val_loss: 0.6198 - val_accuracy: 0.7794\n","Epoch 40/100\n","623/625 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.7902\n","Epoch 00040: val_accuracy improved from 0.77960 to 0.78650, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5917 - accuracy: 0.7903 - val_loss: 0.6099 - val_accuracy: 0.7865\n","Epoch 41/100\n","622/625 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.7946\n","Epoch 00041: val_accuracy did not improve from 0.78650\n","625/625 [==============================] - 4s 7ms/step - loss: 0.5809 - accuracy: 0.7945 - val_loss: 0.6503 - val_accuracy: 0.7691\n","Epoch 42/100\n","622/625 [============================>.] - ETA: 0s - loss: 0.5688 - accuracy: 0.7988\n","Epoch 00042: val_accuracy did not improve from 0.78650\n","625/625 [==============================] - 4s 7ms/step - loss: 0.5692 - accuracy: 0.7987 - val_loss: 0.6280 - val_accuracy: 0.7795\n","Epoch 43/100\n","624/625 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.8015\n","Epoch 00043: val_accuracy improved from 0.78650 to 0.79000, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5634 - accuracy: 0.8015 - val_loss: 0.6039 - val_accuracy: 0.7900\n","Epoch 44/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.5550 - accuracy: 0.8034\n","Epoch 00044: val_accuracy improved from 0.79000 to 0.79380, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5541 - accuracy: 0.8035 - val_loss: 0.5934 - val_accuracy: 0.7938\n","Epoch 45/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.5457 - accuracy: 0.8054\n","Epoch 00045: val_accuracy improved from 0.79380 to 0.79420, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5464 - accuracy: 0.8050 - val_loss: 0.5987 - val_accuracy: 0.7942\n","Epoch 46/100\n","616/625 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.8066\n","Epoch 00046: val_accuracy improved from 0.79420 to 0.79530, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5410 - accuracy: 0.8062 - val_loss: 0.5908 - val_accuracy: 0.7953\n","Epoch 47/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.5314 - accuracy: 0.8109\n","Epoch 00047: val_accuracy did not improve from 0.79530\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5316 - accuracy: 0.8109 - val_loss: 0.5958 - val_accuracy: 0.7943\n","Epoch 48/100\n","624/625 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.8168\n","Epoch 00048: val_accuracy did not improve from 0.79530\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5234 - accuracy: 0.8166 - val_loss: 0.5957 - val_accuracy: 0.7930\n","Epoch 49/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.5178 - accuracy: 0.8154\n","Epoch 00049: val_accuracy improved from 0.79530 to 0.79810, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5185 - accuracy: 0.8153 - val_loss: 0.5906 - val_accuracy: 0.7981\n","Epoch 50/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.8201\n","Epoch 00050: val_accuracy improved from 0.79810 to 0.80230, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.5064 - accuracy: 0.8199 - val_loss: 0.5753 - val_accuracy: 0.8023\n","Epoch 51/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.4990 - accuracy: 0.8226\n","Epoch 00051: val_accuracy did not improve from 0.80230\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4991 - accuracy: 0.8225 - val_loss: 0.5904 - val_accuracy: 0.7966\n","Epoch 52/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.4924 - accuracy: 0.8247\n","Epoch 00052: val_accuracy improved from 0.80230 to 0.80550, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4929 - accuracy: 0.8246 - val_loss: 0.5701 - val_accuracy: 0.8055\n","Epoch 53/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.4861 - accuracy: 0.8253\n","Epoch 00053: val_accuracy did not improve from 0.80550\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4868 - accuracy: 0.8250 - val_loss: 0.6137 - val_accuracy: 0.7880\n","Epoch 54/100\n","616/625 [============================>.] - ETA: 0s - loss: 0.4820 - accuracy: 0.8284\n","Epoch 00054: val_accuracy did not improve from 0.80550\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4818 - accuracy: 0.8281 - val_loss: 0.5806 - val_accuracy: 0.7994\n","Epoch 55/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.8279\n","Epoch 00055: val_accuracy improved from 0.80550 to 0.80610, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4761 - accuracy: 0.8275 - val_loss: 0.5864 - val_accuracy: 0.8061\n","Epoch 56/100\n","616/625 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8372\n","Epoch 00056: val_accuracy did not improve from 0.80610\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4598 - accuracy: 0.8365 - val_loss: 0.5771 - val_accuracy: 0.8049\n","Epoch 57/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.4594 - accuracy: 0.8357\n","Epoch 00057: val_accuracy improved from 0.80610 to 0.81010, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4592 - accuracy: 0.8353 - val_loss: 0.5579 - val_accuracy: 0.8101\n","Epoch 58/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.8381\n","Epoch 00058: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4512 - accuracy: 0.8383 - val_loss: 0.5850 - val_accuracy: 0.8029\n","Epoch 59/100\n","625/625 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.8427\n","Epoch 00059: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4433 - accuracy: 0.8427 - val_loss: 0.5710 - val_accuracy: 0.8065\n","Epoch 60/100\n","625/625 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8446\n","Epoch 00060: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4390 - accuracy: 0.8446 - val_loss: 0.5757 - val_accuracy: 0.8074\n","Epoch 61/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8414\n","Epoch 00061: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4393 - accuracy: 0.8415 - val_loss: 0.5729 - val_accuracy: 0.8074\n","Epoch 62/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.4273 - accuracy: 0.8474\n","Epoch 00062: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4279 - accuracy: 0.8472 - val_loss: 0.5766 - val_accuracy: 0.8084\n","Epoch 63/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.4232 - accuracy: 0.8484\n","Epoch 00063: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4240 - accuracy: 0.8482 - val_loss: 0.5750 - val_accuracy: 0.8073\n","Epoch 64/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8512\n","Epoch 00064: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4142 - accuracy: 0.8510 - val_loss: 0.5737 - val_accuracy: 0.8064\n","Epoch 65/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.4105 - accuracy: 0.8513\n","Epoch 00065: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4105 - accuracy: 0.8513 - val_loss: 0.5690 - val_accuracy: 0.8097\n","Epoch 66/100\n","619/625 [============================>.] - ETA: 0s - loss: 0.4019 - accuracy: 0.8562\n","Epoch 00066: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4021 - accuracy: 0.8562 - val_loss: 0.5750 - val_accuracy: 0.8066\n","Epoch 67/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8565\n","Epoch 00067: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.4015 - accuracy: 0.8562 - val_loss: 0.5583 - val_accuracy: 0.8097\n","Epoch 68/100\n","620/625 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8611\n","Epoch 00068: val_accuracy did not improve from 0.81010\n","625/625 [==============================] - 4s 6ms/step - loss: 0.3869 - accuracy: 0.8611 - val_loss: 0.5812 - val_accuracy: 0.8070\n","Epoch 69/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8597\n","Epoch 00069: val_accuracy improved from 0.81010 to 0.81180, saving model to best_model.h5\n","625/625 [==============================] - 4s 7ms/step - loss: 0.3915 - accuracy: 0.8599 - val_loss: 0.5667 - val_accuracy: 0.8118\n","Epoch 70/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8614\n","Epoch 00070: val_accuracy did not improve from 0.81180\n","625/625 [==============================] - 4s 6ms/step - loss: 0.3889 - accuracy: 0.8612 - val_loss: 0.5744 - val_accuracy: 0.8078\n","Epoch 71/100\n","617/625 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8670\n","Epoch 00071: val_accuracy did not improve from 0.81180\n","625/625 [==============================] - 4s 6ms/step - loss: 0.3755 - accuracy: 0.8673 - val_loss: 0.5691 - val_accuracy: 0.8113\n","Epoch 72/100\n","618/625 [============================>.] - ETA: 0s - loss: 0.3693 - accuracy: 0.8662\n","Epoch 00072: val_accuracy improved from 0.81180 to 0.81440, saving model to best_model.h5\n","625/625 [==============================] - 4s 6ms/step - loss: 0.3683 - accuracy: 0.8665 - val_loss: 0.5727 - val_accuracy: 0.8144\n","Epoch 00072: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fbsU4p739Ew_"},"source":["3- Training GAN"]},{"cell_type":"code","metadata":{"id":"-aXOykYC86mn"},"source":["# Idea from : https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/\n","# Model coming from: https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n","\n","from keras.initializers import RandomNormal\n","from keras.layers import (Activation,\n","                          BatchNormalization,\n","                          Concatenate,\n","                          Conv2D,\n","                          Conv2DTranspose,\n","                          LeakyReLU)\n","from random import shuffle\n","\n","# define an encoder block\n","def define_encoder_block(layer_in, n_filters, batchnorm=True):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","  # add downsampling layer\n","  g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","  # conditionally add batch normalization\n","  if batchnorm:\n","    g = BatchNormalization()(g, training=True)\n","  # leaky relu activation\n","  g = LeakyReLU(alpha=0.2)(g)\n","  return g\n"," \n","# define a decoder block\n","def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","  # add upsampling layer\n","  g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n","  # add batch normalization\n","  g = BatchNormalization()(g, training=True)\n","  # conditionally add dropout\n","  if dropout:\n","    g = Dropout(0.5)(g, training=True)\n","  # merge with skip connection\n","  g = Concatenate()([g, skip_in])\n","  # relu activation\n","  g = Activation('relu')(g)\n","  return g\n"," \n","# define the standalone generator model\n","def define_generator(image_shape=(32,32,3)):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","  # image input\n","  in_image = Input(shape=image_shape)\n","  # encoder model\n","  e1 = define_encoder_block(in_image, 512, batchnorm=False)\n","  e2 = define_encoder_block(e1, 512)\n","  e3 = define_encoder_block(e2, 512)\n","  e4 = define_encoder_block(e3, 512)\n","  # bottleneck, no batch norm and relu\n","  b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e4)\n","  b = Activation('relu')(b)\n","  # decoder model\n","  d1 = decoder_block(b, e4, 512)\n","  d2 = decoder_block(d1, e3, 512)\n","  d3 = decoder_block(d2, e2, 512)\n","  d4 = decoder_block(d3, e1, 512, dropout=False)\n","  # output\n","  g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d4)\n","  out_image = Activation('tanh')(g)\n","  # define model\n","  model = Model(in_image, out_image)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"McBdbNlXCDpV"},"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model, image_shape = (32,32,3)):\n","\t# make weights in the discriminator not trainable\n","\td_model.trainable = False\n","\t# define the source image\n","\ttrue_images = Input(shape=image_shape)\n","\t#connect the source image to the generator input\n","\tfake_images = g_model(true_images)\n","\t# connect the source input and generator output to the discriminator input\n","\td_output = d_model(fake_images)\n","\tfake_labels = tf.math.argmax(d_output)\n","\ttrue_labels = Input(shape= fake_labels.shape)\n","\tconfidence = tf.math.maximum(d_output, 1)\n","\t# src image as input, generated image and classification output\n","\tmodel = Model(inputs = [true_images, true_labels], outputs = [true_images, fake_images, true_labels, fake_labels, confidence])\n","\t# compile model\n","\topt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss = {'true_images' : custom_loss, \n","\t                      'fake_images' : custom_loss,\n","\t\t\t\t\t\t\t\t\t\t\t\t'true_labels': custom_loss,\n","\t\t\t\t\t\t\t\t\t\t\t\t'fake_labels': custom_loss,\n","\t\t\t\t\t\t\t\t\t\t\t\t'confidence' : custom_loss}, optimizer=opt)\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCR8isDCT-9X"},"source":["def custom_loss(true_images, fake_images, true_labels, fake_labels, confidence):\n","  test = true_images-fake_images\n","  distances = np.array([np.linalg.norm(x) for x in test])\n","  label_correctness = (true_labels != fake_labels)\n","  loss = label_correctness*distances + (1-label_correctness)*confidence\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agW6pFJ4UMc-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AixQiAeAJCCa"},"source":["def train_gan(d_model, g_model, x_train, y_train, epochs = 20, batch_size = 256):\n","  for epoch in range(epochs):\n","    print('Running epoch {}'.format(epoch))\n","    #Manually enumerate batch\n","    start_idx = 0\n","    while len(x_train[start_idx*batch_size:]>=batch_size):\n","      if start_idx%10 ==0:\n","        print(start_idx)\n","      true_images = x_train[start_idx*batch_size:(start_idx+1)*batch_size]\n","      true_labels = y_train[start_idx:start_idx+batch_size]\n","      fake_images = g_model.predict(true_images)\n","      #d_output = model.predict(fake_images)\n","      #Train model\n","      g_loss, _, _ = gan_model.train_on_batch([true_images, true_labels], true_labels)\n","      start_idx +=1\n","    #generate last fake images\n","    true_images = x_train[start_idx:]\n","    true_labels = y_train[start_idx:]\n","    #fake_images = g_model.predict(true_images)\n","    #d_output = model.predict(fake_images)\n","    #fake_labels = d_output.argmax()\n","    #confidence = np.max(d_output, axis = 1)\n","    #Calculate loss\n","    g_loss, _, _ = gan_model.train_on_batch([true_images, true_labels], true_labels)\n","\n","    print('Shuffling training set')\n","    random_idx = np.arange(len(x_train))\n","    shuffle(random_idx)\n","    x_train = x_train[random_idx]\n","    y_train = y_train[random_idx]\n","    start_idx = 0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":876},"id":"caAdZScDQVLp","executionInfo":{"status":"error","timestamp":1606830441698,"user_tz":-60,"elapsed":2641,"user":{"displayName":"Barbieri Matteo","photoUrl":"","userId":"12756688091763181975"}},"outputId":"81b66ed8-17f2-4dd0-9743-0a317ec56e8a"},"source":["# define the models\n","d_model = model\n","g_model = define_generator()\n","# define the composite model\n","gan_model = define_gan(g_model, d_model)\n","# train model\n","train_gan(d_model, g_model, x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running epoch 0\n","0\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-05c8c9a1fb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-e346a7576a75>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(d_model, g_model, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m#d_output = model.predict(fake_images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m#Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mstart_idx\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#generate last fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__\n        self.build(y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:139 build\n        self._losses = self._conform_to_outputs(y_pred, self._losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:63 _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:588 map_to_output_names\n        struct.keys(), output_names))\n\n    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['true_images', 'fake_images', 'true_labels', 'fake_labels', 'confidence']). Expected: ['input_3', 'functional_1', 'input_4', 'tf_op_layer_ArgMax', 'tf_op_layer_Maximum']\n"]}]},{"cell_type":"markdown","metadata":{"id":"i7vFOeMFBlfw"},"source":["4- Evaluate on train and test set "]},{"cell_type":"code","metadata":{"id":"H7UFPIN1CCTW"},"source":["print(\"Base accuracy on regular train images:\", model.evaluate(x=x_train, y=y_train, verbose=0)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBCLf1QjCYaF"},"source":["print(\"Base accuracy on regular test images:\", model.evaluate(x=x_test, y=y_test, verbose=0)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mcpA4nGI3uix"},"source":["4 - Generate FGSM ATTACK"]},{"cell_type":"markdown","metadata":{"id":"oPfftJMvfYYg"},"source":["Example on one image\n","\n"]},{"cell_type":"code","metadata":{"id":"CUvwNnvOpdx6"},"source":["image = x_train[1,:]\n","image_label = y_train[1,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFYi161weUI3"},"source":["perturbations = adversarial_pattern(model, image.reshape((-1,32,32,3)), image_label).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUKg3ldwei7r"},"source":["adversarial = image + perturbations * 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2vaYpkRfby7"},"source":["fig=plt.figure(figsize=(10,5))\n","subplot = fig.add_subplot(1,2,1)\n","plt.imshow(image.reshape(32,32,3))\n","subplot.title.set_text(\"An original image\")\n","subplot = fig.add_subplot(1,2,2)\n","plt.imshow(adversarial.reshape(32,32,3))\n","subplot.title.set_text(\"An FGSM attack\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zCbSyyPflTz"},"source":["print('The predicted class of the original image ===>',classes[model.predict(image.reshape(-1,32,32,3)).argmax()])\n","print('The predicted class of the adversarial image===>', classes[model.predict(adversarial).argmax()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LG471FHEjlD7"},"source":["Compute the accuracy of the model on adversarial examples only :"]},{"cell_type":"code","metadata":{"id":"9iqM2FG5hnTG"},"source":["accuracy_FGSM = 0\n","for i in range(x_test.shape[0]) : \n","  image = x_test[i]\n","  image_label = y_test[i].argmax()\n","  perturbations = adversarial_pattern(model, image.reshape((-1,32,32,3)), image_label).numpy()\n","  adversarial = image + perturbations * 0.1\n","  predicted = model.predict(adversarial).argmax()\n","  if predicted == image_label : \n","    accuracy_FGSM+=1\n","accuracy_FGSM = accuracy_FGSM/x_test.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkxsYON0l_Ov"},"source":["accuracy_FGSM"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPaDYwb_l1Dk"},"source":["'The accuracy on test set dropped from approximately 81.2% to 48.7%"]},{"cell_type":"code","metadata":{"id":"O3a5GwF7j1lQ"},"source":[""],"execution_count":null,"outputs":[]}]}