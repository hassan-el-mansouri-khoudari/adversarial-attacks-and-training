{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCRGUsR0oj_3"
      },
      "source": [
        "<center> Adversarial attacks <center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66gNbeg56JDk",
        "outputId": "068adbec-7c17-4de8-99ce-a9baebefb23f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVYtwIZuyBhg",
        "outputId": "301a8c03-f7c4-45bc-8b4f-59c81236ec0e"
      },
      "source": [
        "import os\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks/assignment_3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/assignment_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgtqlXstMCdc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from cifar_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTwnGf28oCLj"
      },
      "source": [
        "1- Import the cifar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHdSGnFToFUw",
        "outputId": "5241a85d-b06e-4aaf-da15-0dbe28e0b7fa"
      },
      "source": [
        "x_train, train_labels, x_test, test_labels = load_CIFAR10_data()\n",
        "classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAIGKd4poUwq"
      },
      "source": [
        "#plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFBALtYMobhv"
      },
      "source": [
        "2- Train a base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOe9UUlkmGNX"
      },
      "source": [
        "input_shape = (32,32,3)\n",
        "model = build_model_base_CNN(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ITv10wcmNr-"
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biz2Bi_1n86r",
        "outputId": "7aece465-b9d0-4e50-ed39-81deca7b582e"
      },
      "source": [
        "## hot encoding of the labels\n",
        "y_train = keras.utils.to_categorical(train_labels, 10) \n",
        "y_test = keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=15)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=64,verbose=1,validation_split = 0.2,callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 2.0691 - accuracy: 0.2314\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32920, saving model to best_model.h5\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 2.0673 - accuracy: 0.2318 - val_loss: 1.8622 - val_accuracy: 0.3292\n",
            "Epoch 2/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.7515 - accuracy: 0.3566\n",
            "Epoch 00002: val_accuracy improved from 0.32920 to 0.40860, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.7507 - accuracy: 0.3572 - val_loss: 1.6233 - val_accuracy: 0.4086\n",
            "Epoch 3/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.6138 - accuracy: 0.4071\n",
            "Epoch 00003: val_accuracy improved from 0.40860 to 0.46440, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.6131 - accuracy: 0.4074 - val_loss: 1.4872 - val_accuracy: 0.4644\n",
            "Epoch 4/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.4438\n",
            "Epoch 00004: val_accuracy improved from 0.46440 to 0.47900, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.5165 - accuracy: 0.4437 - val_loss: 1.4650 - val_accuracy: 0.4790\n",
            "Epoch 5/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.4439 - accuracy: 0.4714\n",
            "Epoch 00005: val_accuracy improved from 0.47900 to 0.51530, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.4441 - accuracy: 0.4713 - val_loss: 1.3546 - val_accuracy: 0.5153\n",
            "Epoch 6/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 1.3803 - accuracy: 0.4968\n",
            "Epoch 00006: val_accuracy improved from 0.51530 to 0.54340, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.3801 - accuracy: 0.4968 - val_loss: 1.2787 - val_accuracy: 0.5434\n",
            "Epoch 7/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.3211 - accuracy: 0.5200\n",
            "Epoch 00007: val_accuracy improved from 0.54340 to 0.55830, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.3216 - accuracy: 0.5199 - val_loss: 1.2276 - val_accuracy: 0.5583\n",
            "Epoch 8/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.2757 - accuracy: 0.5418\n",
            "Epoch 00008: val_accuracy improved from 0.55830 to 0.58170, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2768 - accuracy: 0.5411 - val_loss: 1.1619 - val_accuracy: 0.5817\n",
            "Epoch 9/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.2150 - accuracy: 0.5631\n",
            "Epoch 00009: val_accuracy improved from 0.58170 to 0.60900, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2153 - accuracy: 0.5629 - val_loss: 1.0925 - val_accuracy: 0.6090\n",
            "Epoch 10/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.1688 - accuracy: 0.5812\n",
            "Epoch 00010: val_accuracy improved from 0.60900 to 0.62660, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1693 - accuracy: 0.5810 - val_loss: 1.0482 - val_accuracy: 0.6266\n",
            "Epoch 11/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.1156 - accuracy: 0.6016\n",
            "Epoch 00011: val_accuracy improved from 0.62660 to 0.63300, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1154 - accuracy: 0.6014 - val_loss: 1.0257 - val_accuracy: 0.6330\n",
            "Epoch 12/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.0774 - accuracy: 0.6159\n",
            "Epoch 00012: val_accuracy improved from 0.63300 to 0.64760, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0780 - accuracy: 0.6156 - val_loss: 0.9841 - val_accuracy: 0.6476\n",
            "Epoch 13/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.0484 - accuracy: 0.6278\n",
            "Epoch 00013: val_accuracy improved from 0.64760 to 0.66500, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0489 - accuracy: 0.6277 - val_loss: 0.9406 - val_accuracy: 0.6650\n",
            "Epoch 14/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 1.0188 - accuracy: 0.6367\n",
            "Epoch 00014: val_accuracy did not improve from 0.66500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0184 - accuracy: 0.6370 - val_loss: 0.9612 - val_accuracy: 0.6600\n",
            "Epoch 15/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.9912 - accuracy: 0.6491\n",
            "Epoch 00015: val_accuracy improved from 0.66500 to 0.68820, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9918 - accuracy: 0.6489 - val_loss: 0.8901 - val_accuracy: 0.6882\n",
            "Epoch 16/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.9633 - accuracy: 0.6577\n",
            "Epoch 00016: val_accuracy improved from 0.68820 to 0.69380, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9627 - accuracy: 0.6579 - val_loss: 0.8685 - val_accuracy: 0.6938\n",
            "Epoch 17/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.9420 - accuracy: 0.6650\n",
            "Epoch 00017: val_accuracy improved from 0.69380 to 0.70470, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9423 - accuracy: 0.6651 - val_loss: 0.8549 - val_accuracy: 0.7047\n",
            "Epoch 18/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.9163 - accuracy: 0.6750\n",
            "Epoch 00018: val_accuracy improved from 0.70470 to 0.70960, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9162 - accuracy: 0.6749 - val_loss: 0.8291 - val_accuracy: 0.7096\n",
            "Epoch 19/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.9038 - accuracy: 0.6805\n",
            "Epoch 00019: val_accuracy improved from 0.70960 to 0.71050, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9031 - accuracy: 0.6809 - val_loss: 0.8206 - val_accuracy: 0.7105\n",
            "Epoch 20/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.8814 - accuracy: 0.6875\n",
            "Epoch 00020: val_accuracy did not improve from 0.71050\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8813 - accuracy: 0.6874 - val_loss: 0.8279 - val_accuracy: 0.7062\n",
            "Epoch 21/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.8542 - accuracy: 0.6981\n",
            "Epoch 00021: val_accuracy improved from 0.71050 to 0.72250, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8535 - accuracy: 0.6986 - val_loss: 0.7994 - val_accuracy: 0.7225\n",
            "Epoch 22/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.8440 - accuracy: 0.6993\n",
            "Epoch 00022: val_accuracy improved from 0.72250 to 0.72810, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8448 - accuracy: 0.6992 - val_loss: 0.7790 - val_accuracy: 0.7281\n",
            "Epoch 23/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.8330 - accuracy: 0.7024\n",
            "Epoch 00023: val_accuracy did not improve from 0.72810\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8328 - accuracy: 0.7026 - val_loss: 0.7840 - val_accuracy: 0.7258\n",
            "Epoch 24/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.8148 - accuracy: 0.7097\n",
            "Epoch 00024: val_accuracy did not improve from 0.72810\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8147 - accuracy: 0.7098 - val_loss: 0.7904 - val_accuracy: 0.7232\n",
            "Epoch 25/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.7955 - accuracy: 0.7152\n",
            "Epoch 00025: val_accuracy improved from 0.72810 to 0.73540, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7954 - accuracy: 0.7153 - val_loss: 0.7549 - val_accuracy: 0.7354\n",
            "Epoch 26/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.7845 - accuracy: 0.7200\n",
            "Epoch 00026: val_accuracy improved from 0.73540 to 0.74600, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7841 - accuracy: 0.7203 - val_loss: 0.7224 - val_accuracy: 0.7460\n",
            "Epoch 27/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7707 - accuracy: 0.7260\n",
            "Epoch 00027: val_accuracy improved from 0.74600 to 0.74730, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7708 - accuracy: 0.7262 - val_loss: 0.7287 - val_accuracy: 0.7473\n",
            "Epoch 28/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7558 - accuracy: 0.7302\n",
            "Epoch 00028: val_accuracy did not improve from 0.74730\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7554 - accuracy: 0.7303 - val_loss: 0.7416 - val_accuracy: 0.7431\n",
            "Epoch 29/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7380 - accuracy: 0.7390\n",
            "Epoch 00029: val_accuracy improved from 0.74730 to 0.75370, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7384 - accuracy: 0.7388 - val_loss: 0.7106 - val_accuracy: 0.7537\n",
            "Epoch 30/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7312 - accuracy: 0.7405\n",
            "Epoch 00030: val_accuracy did not improve from 0.75370\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7319 - accuracy: 0.7403 - val_loss: 0.7061 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.7125 - accuracy: 0.7479\n",
            "Epoch 00031: val_accuracy improved from 0.75370 to 0.75400, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7120 - accuracy: 0.7480 - val_loss: 0.7020 - val_accuracy: 0.7540\n",
            "Epoch 32/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7036 - accuracy: 0.7517\n",
            "Epoch 00032: val_accuracy improved from 0.75400 to 0.75710, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.7030 - accuracy: 0.7520 - val_loss: 0.6939 - val_accuracy: 0.7571\n",
            "Epoch 33/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.7539\n",
            "Epoch 00033: val_accuracy improved from 0.75710 to 0.76460, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6955 - accuracy: 0.7539 - val_loss: 0.6748 - val_accuracy: 0.7646\n",
            "Epoch 34/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6846 - accuracy: 0.7560\n",
            "Epoch 00034: val_accuracy improved from 0.76460 to 0.76730, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6845 - accuracy: 0.7561 - val_loss: 0.6675 - val_accuracy: 0.7673\n",
            "Epoch 35/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6686 - accuracy: 0.7633\n",
            "Epoch 00035: val_accuracy did not improve from 0.76730\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6684 - accuracy: 0.7633 - val_loss: 0.7010 - val_accuracy: 0.7595\n",
            "Epoch 36/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.7669\n",
            "Epoch 00036: val_accuracy improved from 0.76730 to 0.76990, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6601 - accuracy: 0.7669 - val_loss: 0.6547 - val_accuracy: 0.7699\n",
            "Epoch 37/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.6437 - accuracy: 0.7717\n",
            "Epoch 00037: val_accuracy improved from 0.76990 to 0.77070, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6439 - accuracy: 0.7717 - val_loss: 0.6604 - val_accuracy: 0.7707\n",
            "Epoch 38/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.7702\n",
            "Epoch 00038: val_accuracy did not improve from 0.77070\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6448 - accuracy: 0.7699 - val_loss: 0.6808 - val_accuracy: 0.7641\n",
            "Epoch 39/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6301 - accuracy: 0.7769\n",
            "Epoch 00039: val_accuracy improved from 0.77070 to 0.78060, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6300 - accuracy: 0.7768 - val_loss: 0.6361 - val_accuracy: 0.7806\n",
            "Epoch 40/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.7819\n",
            "Epoch 00040: val_accuracy improved from 0.78060 to 0.78180, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6147 - accuracy: 0.7819 - val_loss: 0.6284 - val_accuracy: 0.7818\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.7849\n",
            "Epoch 00041: val_accuracy improved from 0.78180 to 0.78220, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6093 - accuracy: 0.7849 - val_loss: 0.6259 - val_accuracy: 0.7822\n",
            "Epoch 42/100\n",
            "618/625 [============================>.] - ETA: 0s - loss: 0.5965 - accuracy: 0.7870\n",
            "Epoch 00042: val_accuracy improved from 0.78220 to 0.78970, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5974 - accuracy: 0.7870 - val_loss: 0.6091 - val_accuracy: 0.7897\n",
            "Epoch 43/100\n",
            "618/625 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.7890\n",
            "Epoch 00043: val_accuracy did not improve from 0.78970\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5931 - accuracy: 0.7889 - val_loss: 0.6284 - val_accuracy: 0.7798\n",
            "Epoch 44/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5835 - accuracy: 0.7925\n",
            "Epoch 00044: val_accuracy did not improve from 0.78970\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5833 - accuracy: 0.7925 - val_loss: 0.6151 - val_accuracy: 0.7867\n",
            "Epoch 45/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.5706 - accuracy: 0.7983\n",
            "Epoch 00045: val_accuracy did not improve from 0.78970\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5708 - accuracy: 0.7981 - val_loss: 0.6071 - val_accuracy: 0.7894\n",
            "Epoch 46/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5699 - accuracy: 0.7979\n",
            "Epoch 00046: val_accuracy did not improve from 0.78970\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5696 - accuracy: 0.7980 - val_loss: 0.6377 - val_accuracy: 0.7801\n",
            "Epoch 47/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5548 - accuracy: 0.8013\n",
            "Epoch 00047: val_accuracy did not improve from 0.78970\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5547 - accuracy: 0.8013 - val_loss: 0.6156 - val_accuracy: 0.7886\n",
            "Epoch 48/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.5493 - accuracy: 0.8060\n",
            "Epoch 00048: val_accuracy improved from 0.78970 to 0.79240, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5487 - accuracy: 0.8062 - val_loss: 0.5996 - val_accuracy: 0.7924\n",
            "Epoch 49/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.8085\n",
            "Epoch 00049: val_accuracy did not improve from 0.79240\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5424 - accuracy: 0.8085 - val_loss: 0.6304 - val_accuracy: 0.7854\n",
            "Epoch 50/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.8106\n",
            "Epoch 00050: val_accuracy improved from 0.79240 to 0.79370, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5326 - accuracy: 0.8105 - val_loss: 0.5977 - val_accuracy: 0.7937\n",
            "Epoch 51/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.5246 - accuracy: 0.8148\n",
            "Epoch 00051: val_accuracy did not improve from 0.79370\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5240 - accuracy: 0.8151 - val_loss: 0.6006 - val_accuracy: 0.7936\n",
            "Epoch 52/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.8144\n",
            "Epoch 00052: val_accuracy did not improve from 0.79370\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5208 - accuracy: 0.8145 - val_loss: 0.5951 - val_accuracy: 0.7933\n",
            "Epoch 53/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.8175\n",
            "Epoch 00053: val_accuracy improved from 0.79370 to 0.79430, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5113 - accuracy: 0.8171 - val_loss: 0.5999 - val_accuracy: 0.7943\n",
            "Epoch 54/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.5035 - accuracy: 0.8212\n",
            "Epoch 00054: val_accuracy improved from 0.79430 to 0.79610, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5042 - accuracy: 0.8211 - val_loss: 0.6050 - val_accuracy: 0.7961\n",
            "Epoch 55/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.8249\n",
            "Epoch 00055: val_accuracy did not improve from 0.79610\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4989 - accuracy: 0.8249 - val_loss: 0.6058 - val_accuracy: 0.7934\n",
            "Epoch 56/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4935 - accuracy: 0.8247\n",
            "Epoch 00056: val_accuracy did not improve from 0.79610\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4933 - accuracy: 0.8249 - val_loss: 0.6045 - val_accuracy: 0.7928\n",
            "Epoch 57/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.8279\n",
            "Epoch 00057: val_accuracy did not improve from 0.79610\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4856 - accuracy: 0.8280 - val_loss: 0.6033 - val_accuracy: 0.7961\n",
            "Epoch 58/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.8299\n",
            "Epoch 00058: val_accuracy did not improve from 0.79610\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4766 - accuracy: 0.8297 - val_loss: 0.5965 - val_accuracy: 0.7941\n",
            "Epoch 59/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.8308\n",
            "Epoch 00059: val_accuracy improved from 0.79610 to 0.80340, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4739 - accuracy: 0.8310 - val_loss: 0.5781 - val_accuracy: 0.8034\n",
            "Epoch 60/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8332\n",
            "Epoch 00060: val_accuracy did not improve from 0.80340\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4663 - accuracy: 0.8333 - val_loss: 0.5880 - val_accuracy: 0.7982\n",
            "Epoch 61/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8385\n",
            "Epoch 00061: val_accuracy did not improve from 0.80340\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4522 - accuracy: 0.8383 - val_loss: 0.5906 - val_accuracy: 0.8020\n",
            "Epoch 62/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.8404\n",
            "Epoch 00062: val_accuracy did not improve from 0.80340\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4519 - accuracy: 0.8403 - val_loss: 0.5889 - val_accuracy: 0.8034\n",
            "Epoch 63/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.8395\n",
            "Epoch 00063: val_accuracy did not improve from 0.80340\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4449 - accuracy: 0.8396 - val_loss: 0.5824 - val_accuracy: 0.8023\n",
            "Epoch 64/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8424\n",
            "Epoch 00064: val_accuracy improved from 0.80340 to 0.80570, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4396 - accuracy: 0.8424 - val_loss: 0.5816 - val_accuracy: 0.8057\n",
            "Epoch 65/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8445\n",
            "Epoch 00065: val_accuracy did not improve from 0.80570\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4344 - accuracy: 0.8447 - val_loss: 0.6019 - val_accuracy: 0.7995\n",
            "Epoch 66/100\n",
            "617/625 [============================>.] - ETA: 0s - loss: 0.4274 - accuracy: 0.8455\n",
            "Epoch 00066: val_accuracy improved from 0.80570 to 0.80590, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4264 - accuracy: 0.8460 - val_loss: 0.5923 - val_accuracy: 0.8059\n",
            "Epoch 67/100\n",
            "616/625 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8512\n",
            "Epoch 00067: val_accuracy did not improve from 0.80590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4162 - accuracy: 0.8509 - val_loss: 0.5857 - val_accuracy: 0.8027\n",
            "Epoch 68/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.4125 - accuracy: 0.8541\n",
            "Epoch 00068: val_accuracy did not improve from 0.80590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4125 - accuracy: 0.8540 - val_loss: 0.5762 - val_accuracy: 0.8042\n",
            "Epoch 69/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8551\n",
            "Epoch 00069: val_accuracy improved from 0.80590 to 0.80920, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4065 - accuracy: 0.8551 - val_loss: 0.5761 - val_accuracy: 0.8092\n",
            "Epoch 70/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4025 - accuracy: 0.8553\n",
            "Epoch 00070: val_accuracy did not improve from 0.80920\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4027 - accuracy: 0.8553 - val_loss: 0.5877 - val_accuracy: 0.8062\n",
            "Epoch 71/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.4032 - accuracy: 0.8548\n",
            "Epoch 00071: val_accuracy did not improve from 0.80920\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4029 - accuracy: 0.8552 - val_loss: 0.5840 - val_accuracy: 0.8050\n",
            "Epoch 72/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8579\n",
            "Epoch 00072: val_accuracy did not improve from 0.80920\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3934 - accuracy: 0.8581 - val_loss: 0.5794 - val_accuracy: 0.8081\n",
            "Epoch 73/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8631\n",
            "Epoch 00073: val_accuracy did not improve from 0.80920\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3870 - accuracy: 0.8632 - val_loss: 0.5733 - val_accuracy: 0.8090\n",
            "Epoch 74/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8637\n",
            "Epoch 00074: val_accuracy improved from 0.80920 to 0.81010, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3804 - accuracy: 0.8636 - val_loss: 0.5799 - val_accuracy: 0.8101\n",
            "Epoch 75/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3770 - accuracy: 0.8646\n",
            "Epoch 00075: val_accuracy did not improve from 0.81010\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3777 - accuracy: 0.8644 - val_loss: 0.5859 - val_accuracy: 0.8064\n",
            "Epoch 76/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3710 - accuracy: 0.8674\n",
            "Epoch 00076: val_accuracy did not improve from 0.81010\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3706 - accuracy: 0.8675 - val_loss: 0.5935 - val_accuracy: 0.8061\n",
            "Epoch 77/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8676\n",
            "Epoch 00077: val_accuracy did not improve from 0.81010\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3674 - accuracy: 0.8677 - val_loss: 0.5936 - val_accuracy: 0.8069\n",
            "Epoch 78/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8690\n",
            "Epoch 00078: val_accuracy improved from 0.81010 to 0.81020, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3651 - accuracy: 0.8690 - val_loss: 0.5841 - val_accuracy: 0.8102\n",
            "Epoch 79/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.8703\n",
            "Epoch 00079: val_accuracy did not improve from 0.81020\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3585 - accuracy: 0.8704 - val_loss: 0.5948 - val_accuracy: 0.8091\n",
            "Epoch 80/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8729\n",
            "Epoch 00080: val_accuracy improved from 0.81020 to 0.81290, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3552 - accuracy: 0.8729 - val_loss: 0.5868 - val_accuracy: 0.8129\n",
            "Epoch 81/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8744\n",
            "Epoch 00081: val_accuracy did not improve from 0.81290\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3502 - accuracy: 0.8743 - val_loss: 0.5904 - val_accuracy: 0.8104\n",
            "Epoch 82/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.8751\n",
            "Epoch 00082: val_accuracy did not improve from 0.81290\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3430 - accuracy: 0.8752 - val_loss: 0.5892 - val_accuracy: 0.8127\n",
            "Epoch 83/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.8789\n",
            "Epoch 00083: val_accuracy improved from 0.81290 to 0.81590, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3375 - accuracy: 0.8791 - val_loss: 0.5819 - val_accuracy: 0.8159\n",
            "Epoch 84/100\n",
            "619/625 [============================>.] - ETA: 0s - loss: 0.3328 - accuracy: 0.8786\n",
            "Epoch 00084: val_accuracy did not improve from 0.81590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3336 - accuracy: 0.8784 - val_loss: 0.5778 - val_accuracy: 0.8136\n",
            "Epoch 85/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.8784\n",
            "Epoch 00085: val_accuracy did not improve from 0.81590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3327 - accuracy: 0.8786 - val_loss: 0.5866 - val_accuracy: 0.8146\n",
            "Epoch 86/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.8847\n",
            "Epoch 00086: val_accuracy did not improve from 0.81590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3221 - accuracy: 0.8847 - val_loss: 0.5863 - val_accuracy: 0.8158\n",
            "Epoch 87/100\n",
            "620/625 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8845\n",
            "Epoch 00087: val_accuracy did not improve from 0.81590\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3229 - accuracy: 0.8845 - val_loss: 0.5880 - val_accuracy: 0.8144\n",
            "Epoch 88/100\n",
            "616/625 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.8822\n",
            "Epoch 00088: val_accuracy improved from 0.81590 to 0.81620, saving model to best_model.h5\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3211 - accuracy: 0.8827 - val_loss: 0.5775 - val_accuracy: 0.8162\n",
            "Epoch 00088: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbsU4p739Ew_"
      },
      "source": [
        "3- Training GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aXOykYC86mn"
      },
      "source": [
        "# Idea from : https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/\n",
        "# Model coming from: https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
        "\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import (Activation,\n",
        "                          BatchNormalization,\n",
        "                          Concatenate,\n",
        "                          Conv2D,\n",
        "                          Conv2DTranspose,\n",
        "                          LeakyReLU)\n",
        "from random import shuffle\n",
        "\n",
        "# define an encoder block\n",
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # add downsampling layer\n",
        "  g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "  # conditionally add batch normalization\n",
        "  if batchnorm:\n",
        "    g = BatchNormalization()(g, training=True)\n",
        "  # leaky relu activation\n",
        "  g = LeakyReLU(alpha=0.2)(g)\n",
        "  return g\n",
        " \n",
        "# define a decoder block\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # add upsampling layer\n",
        "  g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "  # add batch normalization\n",
        "  g = BatchNormalization()(g, training=True)\n",
        "  # conditionally add dropout\n",
        "  if dropout:\n",
        "    g = Dropout(0.5)(g, training=True)\n",
        "  # merge with skip connection\n",
        "  g = Concatenate()([g, skip_in])\n",
        "  # relu activation\n",
        "  g = Activation('relu')(g)\n",
        "  return g\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(image_shape=(32,32,3)):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "  # encoder model\n",
        "  e1 = define_encoder_block(in_image, 512, batchnorm=False)\n",
        "  e2 = define_encoder_block(e1, 512)\n",
        "  e3 = define_encoder_block(e2, 512)\n",
        "  e4 = define_encoder_block(e3, 512)\n",
        "  # bottleneck, no batch norm and relu\n",
        "  b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e4)\n",
        "  b = Activation('relu')(b)\n",
        "  # decoder model\n",
        "  d1 = decoder_block(b, e4, 512)\n",
        "  d2 = decoder_block(d1, e3, 512)\n",
        "  d3 = decoder_block(d2, e2, 512)\n",
        "  d4 = decoder_block(d3, e1, 512, dropout=False)\n",
        "  # output\n",
        "  g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d4)\n",
        "  out_image = Activation('tanh')(g)\n",
        "  # define model\n",
        "  model = Model(in_image, out_image)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K4VTEETAM5r"
      },
      "source": [
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(samples)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McBdbNlXCDpV"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model, image_shape = (32,32,3)):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# define the source image\n",
        "\ttrue_images = Input(shape=image_shape)\n",
        "\t#connect the source image to the generator input\n",
        "\tfake_images = g_model(true_images)\n",
        "\t# connect the source input and generator output to the discriminator input\n",
        "\td_output = d_model(fake_images)\n",
        "\tfake_labels = tf.math.argmax(d_output)\n",
        "\ttrue_labels = Input(shape= fake_labels.shape)\n",
        "\tconfidence = tf.math.maximum(d_output, 1)\n",
        "\t# src image as input, generated image and classification output\n",
        "\tmodel = Model(inputs = [true_images, true_labels], outputs = [true_images, fake_images, true_labels, fake_labels, confidence])\n",
        "\t# compile model\n",
        "\topt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss = custom_loss, optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCR8isDCT-9X"
      },
      "source": [
        "def custom_loss(true_images, fake_images, true_labels, fake_labels, confidence):\n",
        "  test = true_images-fake_images\n",
        "  distances = np.array([np.linalg.norm(x) for x in test])\n",
        "  label_correctness = (true_labels != fake_labels)\n",
        "  loss = label_correctness*distances + (1-label_correctness)*confidence\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agW6pFJ4UMc-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AixQiAeAJCCa"
      },
      "source": [
        "def train_gan(d_model, g_model, x_train, y_train, epochs = 20, batch_size = 256):\n",
        "  for epoch in range(epochs):\n",
        "    print('Running epoch {}'.format(epoch))\n",
        "    #Manually enumerate batch\n",
        "    start_idx = 0\n",
        "    while len(x_train[start_idx*batch_size:]>=batch_size):\n",
        "      if start_idx%10 ==0:\n",
        "        print(start_idx)\n",
        "      true_images = x_train[start_idx*batch_size:(start_idx+1)*batch_size]\n",
        "      true_labels = y_train[start_idx:start_idx+batch_size]\n",
        "      fake_images = g_model.predict(true_images)\n",
        "      #d_output = model.predict(fake_images)\n",
        "      #Train model\n",
        "      g_loss, _, _ = gan_model.train_on_batch([true_images, true_labels], true_labels)\n",
        "      start_idx +=1\n",
        "    #generate last fake images\n",
        "    true_images = x_train[start_idx:]\n",
        "    true_labels = y_train[start_idx:]\n",
        "    #fake_images = g_model.predict(true_images)\n",
        "    #d_output = model.predict(fake_images)\n",
        "    #fake_labels = d_output.argmax()\n",
        "    #confidence = np.max(d_output, axis = 1)\n",
        "    #Calculate loss\n",
        "    g_loss, _, _ = gan_model.train_on_batch([true_images, true_labels], true_labels)\n",
        "\n",
        "    print('Shuffling training set')\n",
        "    random_idx = np.arange(len(x_train))\n",
        "    shuffle(random_idx)\n",
        "    x_train = x_train[random_idx]\n",
        "    y_train = y_train[random_idx]\n",
        "    start_idx = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "caAdZScDQVLp",
        "outputId": "eb4031c7-3179-44c6-9b85-65c0709ae042"
      },
      "source": [
        "# define the models\n",
        "d_model = model\n",
        "g_model = define_generator()\n",
        "# define the composite model\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# train model\n",
        "train_gan(d_model, g_model, x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running epoch 0\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-05c8c9a1fb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-e346a7576a75>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(d_model, g_model, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m#d_output = model.predict(fake_images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m#Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mstart_idx\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#generate last fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n\n    TypeError: tf__custom_loss() missing 3 required positional arguments: 'true_labels', 'fake_labels', and 'confidence'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7vFOeMFBlfw"
      },
      "source": [
        "4- Evaluate on train and test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7UFPIN1CCTW"
      },
      "source": [
        "print(\"Base accuracy on regular train images:\", model.evaluate(x=x_train, y=y_train, verbose=0)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBCLf1QjCYaF"
      },
      "source": [
        "print(\"Base accuracy on regular test images:\", model.evaluate(x=x_test, y=y_test, verbose=0)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcpA4nGI3uix"
      },
      "source": [
        "4 - Generate FGSM ATTACK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPfftJMvfYYg"
      },
      "source": [
        "Example on one image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUvwNnvOpdx6"
      },
      "source": [
        "image = x_train[1,:]\n",
        "image_label = y_train[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFYi161weUI3"
      },
      "source": [
        "perturbations = adversarial_pattern(model, image.reshape((-1,32,32,3)), image_label).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUKg3ldwei7r"
      },
      "source": [
        "adversarial = image + perturbations * 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2vaYpkRfby7"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "subplot = fig.add_subplot(1,2,1)\n",
        "plt.imshow(image.reshape(32,32,3))\n",
        "subplot.title.set_text(\"An original image\")\n",
        "subplot = fig.add_subplot(1,2,2)\n",
        "plt.imshow(adversarial.reshape(32,32,3))\n",
        "subplot.title.set_text(\"An FGSM attack\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zCbSyyPflTz"
      },
      "source": [
        "print('The predicted class of the original image ===>',classes[model.predict(image.reshape(-1,32,32,3)).argmax()])\n",
        "print('The predicted class of the adversarial image===>', classes[model.predict(adversarial).argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG471FHEjlD7"
      },
      "source": [
        "Compute the accuracy of the model on adversarial examples only :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqM2FG5hnTG"
      },
      "source": [
        "accuracy_FGSM = 0\n",
        "for i in range(x_test.shape[0]) : \n",
        "  image = x_test[i]\n",
        "  image_label = y_test[i].argmax()\n",
        "  perturbations = adversarial_pattern(model, image.reshape((-1,32,32,3)), image_label).numpy()\n",
        "  adversarial = image + perturbations * 0.1\n",
        "  predicted = model.predict(adversarial).argmax()\n",
        "  if predicted == image_label : \n",
        "    accuracy_FGSM+=1\n",
        "accuracy_FGSM = accuracy_FGSM/x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkxsYON0l_Ov"
      },
      "source": [
        "accuracy_FGSM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPaDYwb_l1Dk"
      },
      "source": [
        "'The accuracy on test set dropped from approximately 81.2% to 48.7%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3a5GwF7j1lQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}